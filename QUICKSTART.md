# Quick Start Guide

Get the Smart Support Ticket Router up and running in 5 minutes!

## Super Quick Start (Using Make)

```bash
# 1. Clone and setup
git clone <repository-url>
cd smart-support-ticket-router

# 2. One command to rule them all!
make dev

# 3. Start the API
make api
```

**That's it!** API running at http://localhost:8000/docs ðŸŽ‰

---

## Step-by-Step Guide

### Prerequisites

```bash
# Check Python version (need 3.9+)
python --version

# Create virtual environment
python -m venv venv

# Activate it
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 2ï¸Install Dependencies

```bash
# Install all required packages
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### 3ï¸ Set Up Project Structure

```bash
# Create all necessary directories
make setup

# Or manually:
mkdir -p data/{raw,processed,features} models/{saved_models,metrics,experiments} logs
```

### 4ï¸ Generate Training Data

```bash
# Generate 5,000+ synthetic tickets
python scripts/generate_data.py

# Or using Make:
make data
```

**Output:**
- `data/raw/train_tickets.csv` - 5,000 training tickets
- `data/raw/val_tickets.csv` - 1,000 validation tickets
- `data/raw/test_tickets.csv` - 200 test tickets
- `data/raw/ticket_time_series.csv` - 180 days of time series data

### 5ï¸ Train Models

```bash
# Train all models (classifier, forecaster)
python scripts/train_models.py

# Or using Make:
make train
```

**This will:**
1. Train ticket classification model (~45 seconds)
2. Train demand forecasting model (~2 minutes)
3. Test priority detection system
4. Save models to `models/saved_models/`
5. Save metrics to `models/metrics/`

**Expected Performance:**
- Classification Accuracy: 92-95%
- F1-Score: 0.91-0.94
- Forecast MAPE: 8-12%

### 6ï¸ Start the API

```bash
# Development mode (with auto-reload)
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Or using Make:
make api
```

### 7ï¸ Test the API

**Open your browser:**
- **API Docs**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

**Using cURL:**

```bash
# Classify a ticket
curl -X POST "http://localhost:8000/api/v1/predict/classify" \
  -H "Authorization: Bearer test-token-123" \
  -H "Content-Type: application/json" \
  -d '{
    "subject": "Cannot login to my account",
    "description": "I have been trying to log in for 2 hours but keep getting error 401. This is blocking my entire team!",
    "customer_tier": "business"
  }'

# Get demand forecast
curl -X POST "http://localhost:8000/api/v1/forecast/demand" \
  -H "Authorization: Bearer test-token-123" \
  -H "Content-Type: application/json" \
  -d '{
    "days": 7
  }'
```

**Using Python:**

```python
import requests

# API endpoint
url = "http://localhost:8000/api/v1/predict/classify"
headers = {
    "Authorization": "Bearer test-token-123",
    "Content-Type": "application/json"
}

# Ticket data
ticket = {
    "subject": "Payment failed",
    "description": "My credit card was declined when trying to renew subscription",
    "customer_tier": "business"
}

# Make request
response = requests.post(url, json=ticket, headers=headers)
result = response.json()

print(f"Category: {result['category']}")
print(f"Priority: {result['priority']}")
print(f"Confidence: {result['confidence']:.2%}")
print(f"Suggested Team: {result['suggested_team']}")
```

---

## Docker Quick Start

```bash
# Build and run with Docker Compose
docker-compose up -d

# Check logs
docker-compose logs -f api

# Stop services
docker-compose down
```

**Services:**
- API: http://localhost:8000
- PostgreSQL: localhost:5432
- Redis: localhost:6379
- MLflow: http://localhost:5000

---

## Running Tests

```bash
# Run all tests
pytest tests/ -v

# With coverage report
pytest tests/ --cov=src --cov-report=html

# Quick tests only
make test-quick
```

---

## Common Tasks

### Train Models from Real Data

```python
import pandas as pd
from src.models.classifier import TicketClassifier

# Load your data
df = pd.read_csv('your_tickets.csv')

# Required columns: subject, description, category
classifier = TicketClassifier()
classifier.fit(df, target_col='category')
classifier.save('models/saved_models/classifier_v1.pkl',
               'models/saved_models/vectorizer_v1.pkl')
```

### Update API Token

```bash
# Edit .env file
nano .env

# Update this line:
API_TOKENS=your-secure-token-here,another-token

# Restart API
make api
```

### View Model Performance

```bash
# Check saved metrics
cat models/metrics/classifier_metrics.json

# Or in Python
import json
with open('models/metrics/classifier_metrics.json') as f:
    metrics = json.load(f)
    print(f"Accuracy: {metrics['accuracy']:.2%}")
```

---

## Example Use Cases

### 1. Auto-Route Support Tickets

```python
# Classify incoming ticket
result = classifier.predict_single(
    subject=email_subject,
    description=email_body
)

# Route to appropriate team
if result['category'] == 'Technical Support':
    assign_to_team('engineering')
elif result['category'] == 'Billing & Payments':
    assign_to_team('finance')
```

### 2. Priority Triage

```python
from src.models.priority_detector import PriorityDetector

detector = PriorityDetector()
priority = detector.predict_priority(
    subject=ticket.subject,
    description=ticket.description,
    customer_tier=customer.tier
)

if priority['priority'] == 'critical':
    send_sms_alert(on_call_engineer)
    escalate_immediately()
```

### 3. Resource Planning

```python
from src.models.forecaster import TicketForecaster

forecaster = TicketForecaster()
forecast = forecaster.forecast(periods=7)

# Plan staffing based on forecast
for _, row in forecast.iterrows():
    if row['forecast'] > 100:
        schedule_extra_staff(row['date'])
```

---

## Troubleshooting

### Issue: "Model not found"
**Solution:** Run `make train` to train models first

### Issue: "Port 8000 already in use"
**Solution:** 
```bash
# Find and kill process
lsof -i :8000
kill -9 <PID>

# Or use different port
uvicorn src.api.main:app --port 8001
```

### Issue: "Module not found"
**Solution:**
```bash
# Reinstall dependencies
pip install -r requirements.txt

# Check Python path
echo $PYTHONPATH
```

### Issue: Low model accuracy
**Solution:**
- Generate more training data (increase n_tickets)
- Use real historical data instead of synthetic
- Tune hyperparameters in config/config.yaml
- Increase max_features in TF-IDF vectorizer

---

## Project Status Check

```bash
# Check what's set up
make status

# Expected output:
# Data:
#   âœ“ Raw data directory exists
#   âœ“ Training data exists
# Models:
#   âœ“ Classifier trained
#   âœ“ Forecaster trained
# Docker:
#   âœ“ Docker image exists
#   âœ“ Services running
```

---

##  Next Steps

1. **Customize Categories** - Edit `src/data/data_generator.py` to match your ticket types
2. **Add More Features** - Extend feature engineering in `src/features/`
3. **Integrate with Tools** - Connect to Zendesk, Jira, or your ticketing system
4. **Monitor Performance** - Set up MLflow for experiment tracking
5. **Deploy to Production** - Use Docker + Kubernetes for scaling

---

##  Additional Resources

- **API Documentation**: http://localhost:8000/docs
- **Full Documentation**: `docs/`
- **Architecture Guide**: `docs/ARCHITECTURE.md`
- **Deployment Guide**: `docs/DEPLOYMENT.md`

---

##  Pro Tips

1. **Use Make commands** - They handle complex workflows automatically
2. **Start small** - Test with 100 tickets before scaling to thousands
3. **Monitor regularly** - Check model performance weekly
4. **Version models** - Keep old models when deploying new ones
5. **Test thoroughly** - Run `make check` before deploying

---

##  Need Help?

- Check logs: `tail -f logs/sstr.log`
- Run tests: `make test`
- View API status: http://localhost:8000/health
- Read full docs: `README.md`

---

## Success Checklist

- [ ] Environment set up (`make setup`)
- [ ] Dependencies installed (`make install`)
- [ ] Training data generated (`make data`)
- [ ] Models trained (`make train`)
- [ ] API running (`make api`)
- [ ] Successful test prediction
- [ ] API docs accessible

**All checked?** You're ready to integrate with your system! 